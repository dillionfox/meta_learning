{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tabularmaml import ClinicalDataModel, TabularMAML, generate_fake_datasets, oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load prepared datasets. Most data is\n",
    "X_train = pd.read_csv('X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('y_train.csv', index_col=0)\n",
    "\n",
    "X_test = pd.read_csv('X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('y_test.csv', index_col=0)\n",
    "\n",
    "# Generate synthetic training datasets\n",
    "synthetic_train_x, synthetic_train_y = oversample(X_train, y_train)\n",
    "\n",
    "# Construct object to store data and auto-build basic keras model\n",
    "clinical_data_model = ClinicalDataModel(synthetic_train_x, synthetic_train_y,\n",
    "                                        X_train, y_train,\n",
    "                                        X_test, y_test)\n",
    "\n",
    "maml = TabularMAML(clinical_data_model, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model = maml.intermediate_model\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#base_model.trainable = True\n",
    "#last_dense_layer = [it for it,layer in enumerate(base_model.layers) if isinstance(layer,keras.layers.Dense)][-2]\n",
    "#for layer in base_model.layers[:last_dense_layer]:\n",
    "#    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.clone_model(base_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.FalseNegatives(),\n",
    "                       tf.keras.metrics.AUC(),\n",
    "                       tf.keras.metrics.Precision(),\n",
    "                       tf.keras.metrics.Recall(),\n",
    "                       tf.keras.metrics.TruePositives(),\n",
    "                       tf.keras.metrics.TrueNegatives(),\n",
    "                       tf.keras.metrics.FalsePositives(),\n",
    "                       tf.keras.metrics.FalseNegatives(),\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=maml.clinical_data.specific_train_x,\n",
    "    y=maml.clinical_data.specific_train_y,\n",
    "    batch_size=None,\n",
    "    epochs=500,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    validation_data=(maml.clinical_data.test_x, maml.clinical_data.test_y),\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    # validation_freq=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(x=maml.clinical_data.test_x,\n",
    "               y=maml.clinical_data.test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "data = np.array([_.numpy() for _ in maml.loss_per_epoch])\n",
    "sns.lineplot(x=range(len(data)), y=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('~/data/C800/vis-machine-learning/patient_response/notebooks/y_test.csv', index_col=0)\n",
    "prediction_df = y_test\n",
    "n = prediction_df.shape[0]\n",
    "prediction_df.reset_index(inplace=True, drop=True)\n",
    "prediction_df['source_labels'] = y_test['clinical_benefit']\n",
    "prediction_df.drop('clinical_benefit', axis=1, inplace=True, errors=\"ignore\")\n",
    "prediction_df['probability=1'] = pd.Series(model.predict(X_test).T[0], name='probability=1')\n",
    "prediction_df['probability=0'] = 1-prediction_df['probability=1']\n",
    "prediction_df['target_labels'] = prediction_df['probability=1'].apply(lambda x: np.round(x,0))\n",
    "prediction_df['pair_str'] = prediction_df.apply(lambda row: ''.join([row['source_labels'].astype(int).astype(str),row['target_labels'].astype(int).astype(str)]),axis=1)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the empirical joint distribution\n",
    "joint_dist_dict = dict()\n",
    "label_set = ['0', '1']\n",
    "conditional_pairs = ['00', '01', '10', '11']\n",
    "for pair in conditional_pairs:\n",
    "    pair_df = prediction_df[prediction_df['pair_str'] == pair]\n",
    "    joint_dist_dict[pair] = pair_df['probability={}'.format(pair[0])].sum()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the empirical marginal distribution\n",
    "marginal_dist_dict = dict()\n",
    "for y in label_set:\n",
    "    marginal_dist_dict[y] = sum([joint_dist_dict[_] for _ in conditional_pairs if _[-1]==y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the empirical conditional distribution\n",
    "conditional_dist = {key:val/marginal_dist_dict[key[-1]] for key, val in joint_dist_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conditional_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outer_sum = 0\n",
    "for i in range(n):\n",
    "    inner_sum = 0\n",
    "    for z in label_set:\n",
    "        source_label = prediction_df.loc[i]['source_labels'].astype(int).astype(str)\n",
    "        inner_sum += conditional_dist[''.join([source_label, str(z)])] * prediction_df.loc[i]['probability={}'.format(z)]\n",
    "    outer_sum += np.log(inner_sum)\n",
    "# \"From its definition, the LEEP measure is always negative and larger values\n",
    "# (i.e., smaller absolute values) indicate better transferability.\"\n",
    "# LEEP scores tend to range from (-4, -0.5).\n",
    "leep_value = outer_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series([np.round(_[0],0) for _ in base_model.predict(X_test)], name='clinical_benefit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
